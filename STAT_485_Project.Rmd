---
title: "STAT_485_Project"
author: "Team 19"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# STAT 485 Project \| Time Analysis on SALR Data

## Project Background

The real estate market in the Greater Vancouver area has experienced various fluctuations over the past decade. Understanding these changes is crucial for market stakeholders, including investors, realtors, and policy makers.

There is a need for a comprehensive analysis of the *Sales to Active Listings Rate* (SALR) to understand its trends, seasonal patterns, and the probability and impact of extreme market events.

We propose a practical approach by conducting a time series analysis of the SALR from 2011 to 2023. This will include trend analysis, seasonality study, forecasting future values, and particularly focusing on the identification and analysis of extreme events in the market.

## About Dataset

The SALR values are collected and provided by [The Real Estate Board of Greater Vancouver](https://www.rebgv.org/market-watch/monthly-market-report/) (REBGV) for public usages. The REBGV is a member-based professional association of 15,000 REALTORSÂ® and their companies who live and work in communities from Whistler to Maple Ridge to Tsawwassen and everywhere in between.

There are five variables in the dataset:

1.  `Year_month`: the year and month the observations were recorded for
2.  `Reported_SAL`: the SAL rates used in the monthly reports generated by the board
3.  `Sales`: the total number of properties sold during a month
4.  `Listings`: the total number of properties actively listed during a month
5.  `Calculated_SAL`: the SAL rates calculated based on the values of `Sales` and `Listings`.

## Import, Preprocessing, and Preliminary Analysis of Data

Here we perform initial exploratory data analysis (EDA) to understand the basic characteristics of the data. This includes plotting the time series, checking for missing values, and basic descriptive statistics. Our primary focus will be on the feature `Year_month` and `Calculated_SAL`.

```{r echo=FALSE}
library(tidyverse)
library(lubridate)
library(TSA)
library(tseries)
library(forecast)

# Read in SALR dataset
sal_data <- read.csv("SALR_2011_2023.csv",stringsAsFactors = T)

# Convert Year_month to Date type
sal_data$Year_month <- ym(sal_data$Year_month)
summary(sal_data$Year_month)

# Convert SAL percentage to numeric type
sal_data$Calculated_SAL <- as.numeric(sub("%", "", sal_data$Calculated_SAL))
summary(sal_data$Calculated_SAL)

# Create a ts object
SALR_ts <- ts(sal_data$Calculated_SAL, start=c(2011,1), frequency=12)
```

```{r}
plot(SALR_ts, type = "o", main = "Raw Data Plot");abline(h = mean(SALR_ts), col = "blue", lty = 2)
```

From the summary and plot, we have some initial observations:

-   The descriptive statistics show that the average SALR over this period is approximately 25.95%, with a standard deviation of 12.78%. The minimum SALR observed is 8.23%, and the maximum is 70.30%.

-   In the plot, the SALR seems to fluctuate periodically across the years (unlike white noises). There seems to be some seasonality patterns (about every 5 years). There are 2 spikes 60 months apart, where we suspect that they are more likely due to non-recurring events (e.g., property purchase policy changes, or the pandemic) rather than some natural cycles.

-   The series seems to be non-stationary. There are significant swings in SALR over time, indicating a high variability among the data points.

## Trend, Seasonality, and Stationarity Analysis

Due to the nature of the SALR variable, it is unlikely that there exists a deterministic trend where it can applies to the time series forever as the domain of the feature is ranged between 0 and 1. We hypothesize that there is a stochastic seasonal trend and that the time series maybe suitable for seasonal adjustment and/or forecasting using models that can account for both trend and seasonality, such as Multiplicative Seasonal ARIMA (as introduced in Chapter 10). First, we will check if a slightly upward linear trend exists.

### **Testing for a Linear Trend**

Fit a linear model to the data to see if there's a significant linear trend:

```{r}
linearModel <- lm(SALR_ts ~ time(SALR_ts))
plot(SALR_ts);abline(linearModel, col = 'red')
summary(linearModel)
```

-   The model suggests a significant relationship (p=.000342 \< .05) between time and SALR.

-   The coefficient for time (0.9794% per year) is positive, indicating an upward trend over the years.

-   The multiple R-squared value is 0.08116, which implies that about only 8.1% of the variance in SALR can be explained by the time trend alone. This is relatively low, suggesting that other factors (possibly captured in the seasonal or other irregular components such as economic cycles, policy changes, etc.) may play a significant role in explaining the variability in SALR.

-   The F-statistic (13.43) and its p-value (0.0003423\<0.0001) suggest the model is statistically significant.

Generally, if the trend component is significant and persistent over time, even within a bounded series, detrending could be part of the process to achieve stationarity. However, based on the nature of the variable, to preserve the integrity of the data's natural boundaries, and to reflect a realistic understanding of the variable's behavior, we conservatively choose not to detrend the series by removing the linear trend.

### **Identify MA order: ACF**

```{r}
acf(SALR_ts, lag.max = nrow(sal_data))
```

From the sample ACF plot (with unit Year on the x-axis), we find:

-   **Significant Autocorrelation at Various Lags:** The plot shows several spikes (at months 1-15, 26-45, 60, 66-73) that exceed the significance bounds. We also observe that the sample autocorrelation does not exceed the bounds after 73 months (lag 6) and becomes smaller and smaller and eventually stabilizes after 120 months (lag 10).

-   **Seasonal Effects:** The presence of peaks at approximately regular intervals suggests a seasonal pattern. However, these peaks do not seem to occur at each integer lag (i.e., an annual seasonality in this monthly-sampled data), but rather at roughly every 5-6 years. Because the dataset records SARL from January 2011 to October 2023, we are only observing two cycles, which is one of the major limitations we must acknowledge in this time series analysis.

-   **Long Range Dependence:** The fact that the sample autocorrelation function remains significant over many lags (where they slowly taper off but don't cut off sharply) suggests that the series may have long-range dependence or a slowly decaying trend. It suggest that a pure MA process is likely not appropriate (but might need an MA component), and that differencing might be needed to achieve stationarity.

-   **Non-Stationarity:** The slow decay of the autocorrelation function is typical of non-stationary data. For non-stationary series, the ACF typically fails to die out rapidly as the lags increase. There might need some seasonal adjustments on the series.

    -   An additional tool to test stationarity is the Augmented Dickey-Fuller test introduced in Ch 6.4. We may execute `adf.test(SALR_ts)` in the `tseries` package and find that the p-value is .1696, indicating that we do not reject the null hypothesis of non-stationarity.

### **Identify AR order: PACF**

```{r}
pacf(SALR_ts, lag.max = nrow(sal_data))
```

From the sample PACF plot (with unit Year on the x-axis), we find:

-   **Many Non-Significant Lags**: Most lags are within the confidence bounds and are therefore considered non-significant, with a few exceptions at month 1, 11, 13, and 49. There are no values exceeding the noise bounds from month 50 and beyond.

-   **No Clear Seasonal Pattern**: Unlike the sample ACF plot, the sample PACF plot does not show the periodic behavior. Besides the first month (lag .083), the big spike at lag 1 may be hinting that a pure AR(1) may be an appropriate model to start with fitting, or as a non-seasonal component of a potential SARIMA model.

### Identify ARMA orders: EACF

```{r}
eacf(SALR_ts, ar.max = 25, ma.max = 25)
```

The triangle region of zeros shown in the EACF is not a clear cut for lower orders of p and q. We see many x's around 11, 12, and 13, as well as some x's at 23 and 25, indicating a possible 12-month seasonality (with a decaying seasonal effect) in the data generating process. The matrix suggests that ARMA(1,0), ARMA(1,1), or ARMA(2,1) might be a good point to start. The MA(1) model, as expected, does not seem appropriate, while we would nevertheless try to fit it to see if any insights exists.

## Model Selection and Fitting

### Fitting ARMA Models

Initially, we do not apply differencing and assume that the SALR time series is stationary. We try to fit ARMA models (non-seasonal at this point) to look for some insights on the undifferenced data. We will use the dynamics method but starting at MA(1), AR(1), and ARMA(1,1), ignoring an AR(0) model as the series is unlikely to be white noise. Then we check ARMA(2,1) and see if it improved from ARMA(1,1).

```{r}
nb_lag = nrow(sal_data) # 153 rows
ar1 <- arima(SALR_ts, c(1,0,0)) # AIC = 980.33
ma1 <- arima(SALR_ts, c(0,0,1)) # AIC = 1076.17
arma11 <- arima(SALR_ts, c(1,0,1)) # AIC = 978.27
arma21 <- arima(SALR_ts, c(2,0,1)) # AIC = 972.17

# Sample ACF for comparison
acf(sal_data$Calculated_SAL, lag.max=nb_lag)
# summary(ar1)
ar1_y=ARMAacf(ar=c(0.8899),lag.max=nb_lag)
plot(x=1:nb_lag,ar1_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="AR(1)");abline(h=0)
# summary(ma1)
ma1_y=ARMAacf(ma=c(0.8490),lag.max=nb_lag)
plot(x=1:nb_lag,ma1_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="MA(1)");abline(h=0)
# summary(arma11)
arma11_y=ARMAacf(ar=0.8457, ma=0.2187,lag.max=nb_lag)
plot(x=1:nb_lag,arma11_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARMA(1,1)");abline(h=0)
# summary(arma21)
arma21_y=ARMAacf(ar=c(0.3067,0.4832),ma=0.8021,lag.max=nb_lag)
plot(x=1:nb_lag,arma21_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARMA(2,1)");abline(h=0)
# par(mfrow=c(1,1))

# Compare AR(1), ARMA(1,1), and ARMA(2,1) ACF values
# Use the first 16 lags since the sample ACF becomes negative there
acf(sal_data$Calculated_SAL, lag.max=16, plot=FALSE)

# AR(1)
ARMAtoMA(ar = .8899,
         ma = 0,
         lag.max = 16) # 40 lags as it becomes small enough
# ARMA(1,1)
ARMAtoMA(ar = .8457,
         ma = .2187,
         lag.max = 16) # 40 lags as it becomes small enough
# ARMA(2,1)
ARMAtoMA(ar = c(.3067,.4832),
         ma = .8021,
         lag.max = 16) # 40 lags as it becomes small enough
```

The MA(1) is significantly less favorable than the other two as evidenced in the dissimilarity in the ACFs and the highest AIC score of 1076.17 among the models. The sample ACF plot seems to only resemble the ACF plots of the AR(1), ARMA(1,1), and ARMA(2,1) for the first 16 lags, failing to account for any of the periodic patterns beyond. This would be consistent with the earlier analysis that suggested the presence of seasonality or other complex patterns. ARMA(1,1) does not improve significantly from AR(1), while ARMA(2,1) seems to worth further analysis. We will choose AR(1) and AR(2,1) and see what their residuals look like.

```{r}
ar.res = resid(ar1) # Use non-standardized resid() due to the constant variance assumption
plot(y=ar.res,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for AR(1)",type='o')
plot(y=ar.res,x=(SALR_ts - ar.res),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(ar.res, breaks=15, main='Histogram of AR(1) Residuals', xlab= "Residuals")
qqnorm(ar.res);qqline(ar.res, col='red')
acf(ar.res, lag.max = nb_lag, main='ACF of AR(1) Residuals')
pacf(ar.res, lag.max = nb_lag, main='PACF of AR(1) Residuals')
```

The plot of the residuals of the AR(1) model looks a bit more white-noisy with some extremes around year 2011, 2016 and, 2021, indicating that potential periodic trends may still persist.

No apparent systematic pattern (e.g., a funnel shape) shown in the residuals vs fitted values plot, aligning with the assumption of constant variance of errors in the AR(1) model.

The histogram shows approximately symmetrical distribution around zero, suggesting that the model is likely not biased. Potential outliers in the residuals are seen at both tails. The Q-Q plot shows normality in the central part but heavy deviations at the ends of the residuals' distribution, indicating potentially more outliers than a normal distribution would have, which aligns with what we observed in the histogram. These two plots demonstrate that the AR(1) model residuals do not perfectly follow a normal distribution.

The ACF plot shows that most autocorrelations are within the confidence bounds, suggesting that AR(1) has captured the main AR structure of the series. The few big spikes seem to occur around year 1, 2, 4, 5, and 6, indicating that the residuals might not be random and a more complex model (e.g., a SARIMA with a period of 12 months) might be necessary to capture the rest of the pattern.

The AR(1) model appears to be a suitable choice given the sharp cutoff in the PACF plot of the original data, which indicates an AR(1) process is present. Only a few significant spikes with smaller magnitude compared to the sample PACF suggest that the need for additional AR terms might be low. We will test this in subsequent analysis.

```{r}
arma.res = resid(arma21)
plot(y=arma.res,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for ARMA(2,1)",type='o')
plot(y=arma.res,x=(SALR_ts - arma.res),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(arma.res, breaks=15, main='Histogram of ARMA(2,1) Residuals', xlab= "Residuals")
qqnorm(arma.res);qqline(arma.res, col='red')
acf(arma.res, lag.max = nb_lag, main='ACF of ARMA(2,1) Residuals')
pacf(arma.res, lag.max = nb_lag, main='PACF of ARMA(2,1) Residuals')
```

We also compare the residuals between AR(1) and ARMA(2,1) and we see similar results except for a heavier right-skewness in the histogram and an improvement in the ACF and PACF of the ARMA(2,1) residuals, where we observe less spikes in both ACF and PACF in the negative direction. For the level of complexity ARMA(2,1) adds on top of the AR(1) model, we tentatively keep both models as a candidate for adding a seasonal component.

### Fitting Seasonal ARMA Models

Given the results of the AR(1) and ARMA(2,1) residuals analysis, we find it appropriate to add the seasonal component to both models (i.e., a SAMIRA model with difference = 0) of period 12 (i.e., the yearly seasonality seen in the residuals) and 60 months (i.e., the 5-year cycle seen in the observations).

```{r}
# Compared below with summary(ar1) of aic = 979.78
# SARIMA(1,0,0)x(1,0,0)_12
ar1sar1_12 <- arima(SALR_ts, c(1,0,0), list(order=c(1,0,0), period=12)) # AIC = 931.64
# SARIMA(1,0,0)x(0,0,1)_12
ar1sma1_12 <- arima(SALR_ts, c(1,0,0), list(order=c(0,0,1), period=12)) # AIC = 944.05
# SARIMA(1,0,0)x(1,0,1)_12
ar1sarma11_12 <- arima(SALR_ts, c(1,0,0), list(order=c(1,0,1), period=12)) # AIC = 933.49

# SARIMA(1,0,0)x(1,0,0)_60
ar1sar1_60 <- arima(SALR_ts, c(1,0,0), list(order=c(1,0,0), period=60)) # AIC = 951.67
# SARIMA(1,0,0)x(0,0,1)_60
ar1sma1_60 <- arima(SALR_ts, c(1,0,0), list(order=c(0,0,1), period=60)) # AIC = 956.41
# SARIMA(1,0,0)x(1,0,1)_60
ar1sarma11_60 <- arima(SALR_ts, c(1,0,0), list(order=c(1,0,1), period=60)) # AIC = 952.37

# SARIMA(2,0,1)x(1,0,0)_12
arma21sar1_12 <- arima(SALR_ts, c(2,0,1), list(order=c(1,0,0), period=12)) # AIC = 918.58
# SARIMA(2,0,1)x(0,0,1)_12
arma2sma1_12 <- arima(SALR_ts, c(2,0,1), list(order=c(0,0,1), period=12)) # AIC = 938.6
# SARIMA(2,0,1)x(1,0,1)_12
arma21sarma11_12 <- arima(SALR_ts, c(2,0,1), list(order=c(1,0,1), period=12)) # AIC = 920.41
```

We immediately notice that a seasonal period of 60 months does not work here. The sufficiency of an annual seasonality is overriding the needs of trying to look for a 5-year periodic correlation in the time series. In addition, we only have 2 cycles in our dataset, limiting our capability of finding such seasonality. Therefore, from now on we will not be considering a period of 60 months.

The SARIMA $(1,0,0)\times(1,0,0)_{12}$ appears to require least number of parameters among the models yet performs fairly well among the models we considered. It has a non-seasonal AR coefficient of .9, a seasonal AR coefficient of .5, and low standard errors for both terms. Its response function tells us that it forgets 50% of a shock after 7 months, 80% 17 months, and 95% 31 months. This is similar to what we observed in the plot of the raw data points, where the shocks at 2016 and 2021 were impacting for about the next 15-25 months.

```{r}
# Function to compute the impulse response of a seasonal AR(1) model
compute_seasonal_ar1_response <- function(seasonal_ar_coefficient, period, max_lag) {
  # Initialize the response vector with zeros
  response <- rep(0, max_lag)
  
  # The first response occurs at the seasonal lag (e.g., 12 for monthly data)
  response[period] <- seasonal_ar_coefficient
  
  # Calculate the response for subsequent lags
  for (lag in (period + 1):max_lag) {
    # Check if the lag is a multiple of the period
    if ((lag %% period) == 0) {
      response[lag] <- seasonal_ar_coefficient * response[lag - period]
    }
  }
  
  return(response)
}

sar_response <- compute_seasonal_ar1_response(0.5334, 12, 48)
arma_response <- ARMAtoMA(ar=0.9069, ma=0, lag.max = 48)

# Combining the responses
combined_response <- arma_response
non_zero_indices <- which(sar_response != 0)
combined_response[non_zero_indices] <- combined_response[non_zero_indices] * sar_response[non_zero_indices]

plot(combined_response, type="l")
combined_response
```

The SARIMA $(2,0,1)\times(1,0,0)_{12}$ seems to give a better fit. The model has a correaltion of 0.45 and 0.38 for the non-seasonal AR terms, 0.75 for the non-seasonal MA term, and 0.56 correlation every 12 months. However, they receives a low level of significance, indicating a less reliable estimates of the coefficients. The response function suggest that it forgets about 50% of a shock after 8 months, 80% after 15 months, and 95% after 26 months, which aligns better with the observations we see in the actual data plot.

```{r}
sar_response <- compute_seasonal_ar1_response(0.5605, 12, 48)
arma_response <- ARMAtoMA(ar=c(.4536, .3754), ma=.7456, lag.max = 48)

# Combining the responses
combined_response <- arma_response
non_zero_indices <- which(sar_response != 0)
combined_response[non_zero_indices] <- combined_response[non_zero_indices] * sar_response[non_zero_indices]
combined_response

plot(combined_response, type="l")
```

We will examine the residuals for both models to get more insights.

```{r}
sarima100100.res <- resid(ar1sar1_12)
plot(y=sarima100100.res,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for SARIMA(1,0,0)x(1,0,0)_12",type='o')
plot(y=sarima100100.res,x=(SALR_ts - sarima100100.res),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(sarima100100.res, breaks=15, main='Histogram of SARIMA(1,0,0)x(1,0,0)_12 Residuals', xlab= "Residuals")
qqnorm(sarima100100.res);qqline(sarima100100.res, col='red')
acf(sarima100100.res, lag.max = nb_lag, main='ACF of SARIMA(1,0,0)x(1,0,0)_12 Residuals')
pacf(sarima100100.res, lag.max = nb_lag, main='PACF of SARIMA(1,0,0)x(1,0,0)_12 Residuals')


sarima201100.res <- resid(arma21sar1_12)
plot(y=sarima201100.res,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for SARIMA(2,0,1)x(1,0,0)_12",type='o')
plot(y=sarima201100.res,x=(SALR_ts - sarima201100.res),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(sarima201100.res, breaks=15, main='Histogram of SARIMA(2,0,1)x(1,0,0)_12 Residuals', xlab= "Residuals")
qqnorm(sarima201100.res);qqline(sarima201100.res, col='red')
acf(sarima201100.res, lag.max = nb_lag, main='ACF of SARIMA(2,0,1)x(1,0,0)_12 Residuals')
pacf(sarima201100.res, lag.max = nb_lag, main='PACF of SARIMA(2,0,1)x(1,0,0)_12 Residuals')
```

The residuals plots of the two SARIMA model has the same general look. The presence of outliers at 2016 and 2021 in both plots indicates that there might be extraordinary events not captured by either model, or that these could be natural, rare fluctuations in the data.

The histogram of SARIMA(2,0,1)x(1,0,0)12 is more centralized around 0. Its Q-Q plot seems to stay closer to the line at both tails than in SARIMA(1,0,0)x(1,0,0)12 residuals. We reach the conclusion that the SARIMA(2,0,1)x(1,0,0)12 model residuals is better at following a normal distribution.

The ACF and PACF plot of the SARIMA(2,0,1)x(1,0,0)12 model shows a reduction in the amount of significant spikes by about 50% compared to those for the SARIMA(1,0,0)x(1,0,0)12 model. It indicates that the SARIMA(2,0,1)x(1,0,0)12 is capturing more information than the other.

In conclusion, the residual analysis for the SARIMA models seems to suggest that SARIMA(2,0,1)x(1,0,0)12 is a better fit for the data than the SARIMA(1,0,0)x(1,0,0)12 model. The ACF and PACF plot show the sufficiency in the former model to capture most of the patterns in the data, leaving some spikes spikes observed in the plots. The response function of the winner model also mimics more closely to our expectations of how the time series would be responding to a shock, based on how it has responded to the extreme events at 2016 and 2021. Therefore, we would choose SARIMA(2,0,1)x(1,0,0)12 as our best model.

### Exploring Differencing

In our initial analysis, we treated the SALR data as if it were stationary, allowing us to fit stationary ARMA models and incorporate a seasonal component to address potential seasonality. While this approach has provided valuable insights, we acknowledge that, as argued in the stationary analysis, the time series does exhibit non-stationary behavior. To further refine our understanding and model fitting, we investigate the presence of a stochastic trend by applying differencing to the SALR data.

We will begin with identifying the level of differencing and apply the appropriate differencing to remove linear trends to attempt achieving stationarity. This process will possibly lead to an improved SARIMA model that better captures the underlying dynamics of the data.

```{r}
plot(SALR_ts, type="o", main="Original Series Plot")
plot(diff(SALR_ts, differences = 1), type="o", main="First Differencing Series Plot")
plot(diff(SALR_ts, differences = 2), type="o", main="Second Differencing Series Plot")
acf(SALR_ts, lag.max=nb_lag, main="Sample ACF Plot")
pacf(SALR_ts, lag.max=nb_lag, main="Sample PACF Plot")
acf(diff(SALR_ts, differences = 1), lag.max = nb_lag, main="First Differencing ACF Plot")
pacf(diff(SALR_ts, differences = 1), lag.max = nb_lag, main = "First Differencing PACF Plot")
acf(diff(SALR_ts, differences = 2), lag.max = nb_lag, main="Second Differencing ACF Plot")
pacf(diff(SALR_ts, differences = 2), lag.max = nb_lag, main="Second Differencing PACF Plot")
```

From the above plot, we conclude that the first differencing seems more appropriate than the second differencing for several reasons:

-   The second differencing shows signs of over-differencing, which is indicated by the increased number and magnitude of spikes in the ACF plot and the early significant negative spikes in the PACF plot. The over-differencing issue typically manifests as a series of alternating positive and negative spikes in the PACF plot, especially if the underlying process is not of a higher order.

-   The first differencing maintains a reasonable level of variability without introducing the artificial patterns seen in the second differencing.

-   The increase in the number of significant lags in the ACF and PACF for the second differenced series suggests that it may be capturing noise rather than the true signal.

For the first differencing, the ACF plot with 8 significant lags may indicate some remaining autocorrelation, but the overall reduction in autocorrelation is a positive sign. The presence of some significant lags in its PACF plot may suggest the need for additional AR or MA terms to capture the autocorrelation structure. Given these points, we proceed with the first differencing and consider adding AR or MA terms.

### Fitting SARIMA Models

```{r}
# Compared to the best AIC of 931.64 for SARIMA(1,0,0)x(1,0,0)_12
arima110 <- arima(SALR_ts, c(1,1,0)) # AIC = 978.41
arima011 <- arima(SALR_ts, c(0,1,1)) # AIC = 977.97
arima111 <- arima(SALR_ts, c(1,1,1)) # AIC = 971.07
arima211 <- arima(SALR_ts, c(2,1,1)) # AIC = 971.13

# Sample ACF for comparison
acf(sal_data$Calculated_SAL, lag.max=nb_lag)
# summary(arima110)
arima110_y=ARMAacf(ar=c(0.0824),lag.max=nb_lag)
plot(x=1:nb_lag,arima110_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARIMA(1,1,0)");abline(h=0)
# summary(arima011)
arima011_y=ARMAacf(ma=c(0.1196),lag.max=nb_lag)
plot(x=1:nb_lag,arima011_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARIMA(0,1,1)");abline(h=0)
# summary(arima111)
arima111_y=ARMAacf(ar=-0.6016, ma=0.8135,lag.max=nb_lag)
plot(x=1:nb_lag,arima111_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARIMA(1,1,1)");abline(h=0)
# summary(arima211)
arima211_y=ARMAacf(ar=c(-0.6201,-0.1222), ma=0.7701,lag.max=nb_lag)
plot(x=1:nb_lag,arima211_y[-1],ylab=expression(rho[k]),xlab="k",type="h",main="ARIMA(2,1,1)");abline(h=0)
```

We first compare several ARIMA models: ARIMA(1,1,0), ARIMA(0,1,1), ARIMA(1,1,1), and ARIMA(2,1,1). From the ACF plots, we observe that all of the models by themselves are not sufficiently capturing the long-term dependency in the data. However, the ARIMA(1,1,1) model seems to capture more of the complexity in the data more appropriately, as evidenced in the ACF plot with a more pronounced decay across several lags. Therefore, we will advance with ARIMA(1,1,1) for residual analysis.

```{r}
arima.res = resid(arima111)
plot(y=arima.res,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for ARIMA(1,1,1)",type='o')
plot(y=arima.res,x=(SALR_ts - arima.res),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(arima.res, breaks=15, main='Histogram of ARIMA(1,1,1) Residuals', xlab= "Residuals")
qqnorm(arima.res);qqline(arima.res, col='red')
acf(arima.res, lag.max = nb_lag, main='ACF of ARIMA(1,1,1) Residuals')
pacf(arima.res, lag.max = nb_lag, main='PACF of ARIMA(1,1,1) Residuals')
```

We have similar observations as seen in the residual analysis for the AR(1) model, except that (1) the histogram has achieved a closer approximation to the expected bell-shaped curve with the outliers still persist at both tails; (2) the Q-Q plot has a reduction in the deviations from the theoretical quantiles near the right tail; and (3) both ACF and PACF for ARIMA(1,1,1) are only marginally better than those of AR(1) residuals. The similarities in the residuals analysis suggest that the added complexity has not captured substantially more information of the data structure.

Next, we incorporate seasonal components.

```{r}
# Compared below with summary(arma21sar1_12) of aic = 918.58
# SARIMA(1,1,1)x(1,0,0)_12
arima111sar1_12 <- arima(SALR_ts, c(1,1,1), list(order=c(1,0,0), period=12)) # AIC = 916.04
# SARIMA(1,1,1)x(0,0,1)_12
arima111sma1_12 <- arima(SALR_ts, c(1,1,1), list(order=c(0,0,1), period=12)) # AIC = 931.83
# SARIMA(1,1,1)x(1,0,1)_12
arima111sarma11_12 <- arima(SALR_ts, c(1,1,1), list(order=c(1,0,1), period=12)) # AIC = 917.98
# SARIMA(1,1,1)x(1,1,0)_12
arima111sarima110_12 <- arima(SALR_ts, c(1,1,1), list(order=c(1,1,0), period=12)) # AIC = 871.92
# SARIMA(1,1,1)x(0,1,1)_12
arima111sarima011_12 <- arima(SALR_ts, c(1,1,1), list(order=c(0,1,1), period=12)) # AIC = 853.62
# SARIMA(1,1,1)x(1,1,1)_12
arima111sarima111_12 <- arima(SALR_ts, c(1,1,1), list(order=c(1,1,1), period=12)) # AIC = 840.87
```

By incorporating both non-seasonal and seasonal AR components while differencing once, the SARIMA$(1,1,1)\times(1,1,1)_{12}$ model seems to capture the short-term dynamics and the seasonality of the series effectively. Given the substantial improvement in AIC compared to the previously best model's AIC of 918.58 (from SARIMA$(2,0,1)\times(1,0,0)_{12}$, it seems that adding a first differencing in both seasonal and non-seasonal component collectively has significantly improved the fit of the model. In addition, this differenced model has lower standard errors, suggesting more confidence in the coefficient estimates. The lower variance of the residuals also indicates a better fit to the data in terms of explaining the variability. We look at its residuals:

```{r}
sarima.res.2 <- resid(arima111sarima111_12)
plot(y=sarima.res.2,x=as.vector(time(SALR_ts)),xlab='Time',
     ylab='Residuals',main="Residuals for SARIMA(1,1,1)x(1,1,1)_12",type='o')
plot(y=sarima.res.2,x=(SALR_ts - sarima.res.2),ylab='Residuals',
     xlab='Fitted Values',type='p')
hist(sarima.res.2, breaks=15, main='Histogram of SARIMA(1,1,1)x(1,1,1)_12 Residuals', xlab= "Residuals")
qqnorm(sarima.res.2);qqline(sarima.res.2, col='red')
acf(sarima.res.2, lag.max = nb_lag, main='ACF of SARIMA(1,1,1)x(1,1,1)_12 Residuals')
pacf(sarima.res.2, lag.max = nb_lag, main='PACF of SARIMA(1,1,1)x(1,1,1)_12 Residuals')
```

The first couple residuals (up to 2012) closely cluster around zero, suggesting a sign of overfitting where the model captures the noise of the early data too well and do not generalize to the rest of the data or new data. Both the ACF and PACF plots indicate that there are no significant autocorrelations or partial autocorrelations in the residuals, suggesting that the SARIMA(1,1,1)x(1,1,1)[12] model has captured the underlying process well and that the residuals are essentially white noise.

### Selecting the Best Model

In the comparative analysis of the SARIMA(1,1,1)x(1,1,1)[12] and ARIMA(2,0,1)x(1,0,0)[12] models, diagnostic checks including the ACF and PACF indicated that the residuals of both models are close to white noise, suggesting an adequate fit. However, given our practical understanding of the data, where significant spikes in 2016 and 2021 are more likely attributed to non-recurring external events rather than systematic seasonal patterns, a simpler model is favored. The ARIMA(2,0,1)x(1,0,0)[12], while statistically less optimal based on AIC, avoids overfitting by not overemphasizing seasonal differencing, which could inappropriately model these one-off events as seasonal phenomena. This aligns with our theoretical knowledge of the dataset and the specific nature of the observed anomalies. Moreover, the simpler model is preferred for its ease of interpretation, potential robustness in out-of-sample forecasting, and its pragmatic fit with the time series' characteristics, making it a prudent choice for our analytical objectives.

## Simulation

We're simulating 100 series into the future and the simulated series from SARIMA(2,0,1)x(1,0,0)[12] model capture similar patterns with our original time series. These simulations give us an idea of the possible distributions or paths of our observations over time. Most of the simulated series have observations reverted to the rate of 25%, with reasonable fluctuations around the mean. Some simulated series predict extremes that may happen in the next 5-year period.

```{r}
sarima201100.12 <- Arima(SALR_ts, c(2,0,1), list(order=c(1,0,0), period=12))
# Number of simulated series
num_simulations <- 100
acf(simulate(sarima201100.12),main = "Simulation Series ACF 201100",lag.max = nrow(sal_data))
# Generate simulated series with the same frequency as SALR_ts
simulated_yseries <- replicate(num_simulations, simulate(sarima201100.12,nsim=36))

# Extract frequency and start time from SALR_ts
freq_SALR_ts <- frequency(SALR_ts)
start_SALR_ts <- end(SALR_ts)  # Start of the replicated series should start from the end of SALR_ts

simyseries201100 <- lapply(1:num_simulations, function(i) {
  ts(simulated_yseries[, i], frequency = freq_SALR_ts, start = start_SALR_ts)
})

all_series201100 <- cbind(SALR_ts, do.call(cbind, simyseries201100))

sim201100 <-  matplot(all_series201100, main= "Simulated series 201100",type='l', col=c(1, 2:(num_simulations + 1)))
```

## Forecasting and Model Evaluation

### Forecasting on Existing Time Period

One of the major goals of time series analysis is to predict the future data trend with high confidence and accuracy. In the previous section we have detected candidate models that fit the data relatively well, we will now test the model's performance on future data via a training/validation split.Â 

```{r}
# Split the data into training and test sets

train_end <- length(SALR_ts) - 24 # Hold out the last two year for testing

train_set <- head(SALR_ts, train_end)

test_set <- tail(SALR_ts, 24)

ar1 <- Arima(train_set, c(1,0,0))

ar1sar1_12 <- Arima(train_set, c(1,0,0), list(order=c(1,0,0), period=12))

ar21sar1_12 <- Arima(train_set, c(2,0,1), list(order=c(1,0,0), period=12))

forecast.ar1 <- forecast(ar1, h=24)

forecast.ar1sar1_12 <- forecast(ar21sar1_12, h=24)

forecast.ar21sar1_12 <- forecast(ar21sar1_12, h=24)

autoplot(train_set) +

  autolayer(forecast.ar1sar1_12, series = "ARIMA(1,0,0)x(1,0,0)_12") +

  autolayer(test_set, series = "Real Data")

autoplot(train_set) +

  autolayer(forecast.ar1, series = "AR(1)") +

  autolayer(test_set, series = "Real Data")

autoplot(train_set) +

  autolayer(forecast.ar21sar1_12, series = "ARIMA(2,0,1)x(1,0,0)_12") +

  autolayer(test_set, series = "Real Data")
```

From the plot, The ARIMA(2,0,1)x(1,0,0)[12] does well forecasting the data behavior and volatility in the testing period, although it does have a slightly slower mean reversion compared to AR(1) and the real data. We ran a longer training/validation split forecasting the candidate model:

```{r}
# Split the data into training and test sets

train_end <- length(SALR_ts) - 60 # Hold out the last four year for testing

train_set <- head(SALR_ts, train_end)

test_set <- tail(SALR_ts, 60)

ar1 <- Arima(train_set, c(1,0,0))

ar21sar1_12 <- Arima(train_set, c(2,0,1), list(order=c(1,0,0), period=12))

forecast.ar1 <- forecast(ar1, h=60)

forecast.ar21sar1_12 <- forecast(ar21sar1_12, h=60)

autoplot(train_set) +

  autolayer(forecast.ar1, series = "AR(1)") +

  autolayer(test_set, series = "Real Data")

autoplot(train_set) +

  autolayer(forecast.ar21sar1_12, series = "ARIMA(2,0,1)x(1,0,0)_12") +

  autolayer(test_set, series = "Real Data")
```

In the longer forecast, we can see our model perform less well on the dataset. Particularly, although it does revert to the mean, the model no longer captures the volatility as accurately as the 24 month testing set. This may be a sign of overfitting.

### Forecasting on Future Time Period

```{r}
ar21sar1_12 <- Arima(SALR_ts, c(2,0,1), list(order=c(1,0,0), period=12))

autoplot(forecast(ar21sar1_12, h=60))
```

We used our model to predict 5 years into the future. From the forecasting plot, our model suggests that market volatility would still remain high within the first two years, and slowly disappear assuming no major shock happens. It is impossible for our model to predict when or whether a shock would happen, hence it would be necessary for the model to be re-fitted whenever a shock happens for a more reliable forecast over a shock-response .

## Conclusion

Modeling efforts led to the selection of $SARIMA(2,0,1)\times(1,0,0)_{12}$ as the preferred choice due to its ability to cappture short-term dynamics and seasonal patterns. This model, despite a relatively higher AIC compared to $SARIMA(2,0,1)\times(1,0,0)_{12}$, showcased a more reasonable fit by appropriately handling presumably non-recurring shocks in 2016 and 2021 without overfitting.

While proficient in short-term forecasting, the chosen model displayed reduced accuracy in longer forecasts, possibly indicative of overfitting. Predictions suggested a gradual decrease in market volatility, assuming no major shocks.

In conclusion, the $SARIMA(2,0,1)\times(1,0,0)_{12}$ model was favored for its alignment with observed anomalies and practicality. Continuous refinement is crucial for enhancing the model's reliability in predicting the dynamic trends of the Greater Vancouver real estate market.

## Limitation and Recommendation

-   If experts believe that the shocks are regularly recurring events, we might need to re-consider the feasibility of the $SARIMA(1,1,1)\times(1,1,1)_{12}$ model.

-   It is possible to obtain daily/weekly observations instead of monthly. In that case, we may derive different models and insights of how the market will behave in the future.
